{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "848d26e5-256e-4cca-aa48-19ee9233fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "\n",
    "# This block imports the necessary libraries for data manipulation, text processing, machine learning models, and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561202e-c680-4a96-a3f1-d46f38ee5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to iteratively classify documents using the Active Learning strategy\n",
    "def classify_priority_documents(texts, model, tfidf_vectorizer, max_non_relevant_docs=50, labeled_documents=set()):\n",
    "    classified_documents = pd.DataFrame(columns=['Abstract', 'label', 'predicted'])  # Adding the 'predicted' column\n",
    "    non_relevant_consecutive = 0\n",
    "\n",
    "    while len(texts) > 0:\n",
    "        # Filter unlabeled documents\n",
    "        unlabeled_texts = texts[~texts['Abstract'].isin(labeled_documents)]\n",
    "        \n",
    "        # Check if there are unlabeled documents\n",
    "        if len(unlabeled_texts) == 0:\n",
    "            break\n",
    "        \n",
    "        # Select priority documents among the unlabeled\n",
    "        priority_texts, priority_indices = select_priority_documents(unlabeled_texts['Abstract'], model, tfidf_vectorizer, 10)\n",
    "        \n",
    "        # Present priority documents to the user one by one\n",
    "        for i, text in enumerate(priority_texts, start=1):\n",
    "            print(f\"\\nDocument {i}:\")\n",
    "            print(text)\n",
    "            print()\n",
    "            \n",
    "            # Ask the user to label the document\n",
    "            label = input(\"Is this document relevant? (y/n): \").lower()\n",
    "\n",
    "            # Check if the user provided a valid response\n",
    "            while label not in ['y', 'n', '']:\n",
    "                print(\"Please respond with 'y' for yes, 'n' for no, or press Enter to skip.\")\n",
    "                label = input(\"Is this document relevant? (y/n): \").lower()\n",
    "\n",
    "            # If the user presses Enter, the document will be ignored\n",
    "            if label == '':\n",
    "                print(\"Document ignored.\")\n",
    "                continue\n",
    "\n",
    "            # Add the document, label, and prediction to the classified data\n",
    "            prediction = model.predict(tfidf_vectorizer.transform([text]))[0]  # Model prediction\n",
    "            classified_documents = classified_documents.append({'Abstract': text, 'label': label, 'predicted': prediction}, ignore_index=True)\n",
    "            labeled_documents.add(text)  # Add document to labeled\n",
    "            texts = texts.drop(texts.index[priority_indices[i-1]])  # Remove classified document from remaining texts\n",
    "\n",
    "            # Count non-relevant documents\n",
    "            if label == 'n':\n",
    "                non_relevant_consecutive += 1\n",
    "                if non_relevant_consecutive >= max_non_relevant_docs:\n",
    "                    print(f\"\\nReached the limit of {max_non_relevant_docs} consecutive non-relevant documents. Stopping the process.\")\n",
    "                    break\n",
    "            else:\n",
    "                non_relevant_consecutive = 0\n",
    "\n",
    "        if non_relevant_consecutive >= max_non_relevant_docs:\n",
    "            break\n",
    "\n",
    "    return classified_documents\n",
    "\n",
    "# Function to select priority documents\n",
    "def select_priority_documents(texts, model, tfidf_vectorizer, num_docs):\n",
    "    # Calculate class probabilities for the unlabeled documents\n",
    "    class_probabilities = model.predict_proba(tfidf_vectorizer.transform(texts))\n",
    "    # Select indices of documents with the highest probability of being relevant\n",
    "    priority_indices = class_probabilities[:, 1].argsort()[::-1][:num_docs]\n",
    "    # Return the selected texts and indices\n",
    "    return texts.iloc[priority_indices], priority_indices\n",
    "\n",
    "def calculate_recall(classification_results, threshold=0.5):\n",
    "    # Convert predictions to discrete labels using the decision threshold\n",
    "    classification_results['predicted'] = classification_results['predicted'].map({1: 'y', 0: 'n'})\n",
    "    # Calculate classification metrics\n",
    "    recall = recall_score(classification_results['label'], classification_results['predicted'], average='binary', pos_label='y')\n",
    "    tn, fp, fn, tp = confusion_matrix(classification_results['label'], classification_results['predicted']).ravel()\n",
    "    return recall, tp, fp, tn, fn\n",
    "\n",
    "# This block contains all the functions defined for the classification process, including classifying priority documents, selecting priority documents, and calculating recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb93471-b974-426f-9319-f94dadbb31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data of manually labeled studies from a CSV file\n",
    "training_data = pd.read_csv('file.csv')\n",
    "training_data.dropna(subset=['label'], inplace=True)\n",
    "training_texts = training_data['Abstract']\n",
    "training_labels = training_data['label']\n",
    "\n",
    "# Extract features from texts using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(training_texts) \n",
    "\n",
    "# In this block, the data is loaded from a CSV file and prepared for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7435757f-0f76-4516-be2a-159b577f1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model with the training data\n",
    "logistic_model = LogisticRegression(class_weight='balanced')\n",
    "logistic_model.fit(X_train_tfidf, training_labels)\n",
    "\n",
    "# Train the Naive Bayes model with the training data\n",
    "naive_bayes_model = MultinomialNB(alpha=3.822)\n",
    "naive_bayes_model.fit(X_train_tfidf, training_labels)\n",
    "\n",
    "# Load the data of unlabeled studies from a CSV file\n",
    "unlabeled_data = pd.read_csv('file.csv')\n",
    "\n",
    "# Set the threshold of consecutive non-relevant documents\n",
    "max_non_relevant_docs = 50\n",
    "\n",
    "# Call the function to classify priority documents with the Logistic Regression model\n",
    "logistic_classification_results = classify_priority_documents(unlabeled_data, logistic_model, tfidf_vectorizer, max_non_relevant_docs)\n",
    "\n",
    "# Save the classified results to CSV files\n",
    "logistic_classification_results.to_csv('results_lr.csv', index=False)\n",
    "\n",
    "# Call the function to classify priority documents with the Naive Bayes model\n",
    "naive_bayes_classification_results = classify_priority_documents(unlabeled_data, naive_bayes_model, tfidf_vectorizer, max_non_relevant_docs)\n",
    "\n",
    "# Save the classified results to CSV files\n",
    "naive_bayes_classification_results.to_csv('results_nb.csv', index=False)\n",
    "\n",
    "# This block contains the creation and training of logistic regression and naive bayes models based on the training data. The threshold for non-relevant documents is set to stop classification. Finally, the unlabeled documents are loaded and classified using the trained models, with the results saved to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de1a3e-bea0-4e25-8a3d-e955a3e68321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of recall for each algorithm\n",
    "recall_logistic, tp_logistic, fp_logistic, tn_logistic, fn_logistic = calculate_recall(logistic_classification_results)\n",
    "recall_naive_bayes, tp_naive_bayes, fp_naive_bayes, tn_naive_bayes, fn_naive_bayes = calculate_recall(naive_bayes_classification_results)\n",
    "\n",
    "# Print the values\n",
    "print(\"Recall for Logistic Regression:\", recall_logistic)\n",
    "print(\"True Positives (TP) for Logistic Regression:\", tp_logistic)\n",
    "print(\"False Positives (FP) for Logistic Regression:\", fp_logistic)\n",
    "print(\"True Negatives (TN) for Logistic Regression:\", tn_logistic)\n",
    "print(\"False Negatives (FN) for Logistic Regression:\", fn_logistic)\n",
    "print()\n",
    "print(\"Recall for Naive Bayes:\", recall_naive_bayes)\n",
    "print(\"True Positives (TP) for Naive Bayes:\", tp_naive_bayes)\n",
    "print(\"False Positives (FP) for Naive Bayes:\", fp_naive_bayes)\n",
    "print(\"True Negatives (TN) for Naive Bayes:\", tn_naive_bayes)\n",
    "print(\"False Negatives (FN) for Naive Bayes:\", fn_naive_bayes)\n",
    "\n",
    "# Print documents classified as relevant by each model\n",
    "print(\"Documents classified as relevant by the Logistic Regression model:\")\n",
    "print(logistic_classification_results[logistic_classification_results['label'] == 'y']['Abstract'])\n",
    "print(\"Documents classified as relevant by the Naive Bayes model:\")\n",
    "print(naive_bayes_classification_results[naive_bayes_classification_results['label'] == 'y']['Abstract'])\n",
    "\n",
    "# This block provides an analysis of the model performance and the documents classified as relevant by each of them. Additionally, it prints the documents classified as relevant by each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d3605-085d-44d8-90ff-c84d4f19b41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
